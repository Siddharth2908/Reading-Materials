{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pandas\n",
    "import numpy as numpy\n",
    "import os\n",
    "import matplotlib.pyplot as matplot\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import itertools\n",
    "from IPython.display import Image  \n",
    "from sklearn import tree\n",
    "from os import system\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "numpy.random.seed(1234)\n",
    "RandomState = numpy.random.seed(1234)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "class Perform_EDA():\n",
    "    def __init__(self):\n",
    "        self.train_data = None\n",
    "        self.user_id = None\n",
    "        self.item_id = None\n",
    "        \n",
    "    def EDA_Corr(df):\n",
    "        corr = df.corr()\n",
    "        index = corr.columns\n",
    "        Output = []\n",
    "        for i in range(0,len(index)):\n",
    "            i = index[i]\n",
    "            Pos = corr.index[(corr[i] >= 0.5)].tolist()\n",
    "            No = corr.index[(corr[i] < 0.5) & (corr[i] > -0.6)].tolist()\n",
    "            Neg = corr.index[(corr[i] <= -0.5)].tolist()\n",
    "            leng_u = len(No)\n",
    "            leng_pos = len(Pos)\n",
    "            leng_neg = len(Neg)\n",
    "            Out = [i, leng_u, leng_pos, leng_neg, Pos, Neg, No]\n",
    "            Output.append(Out)\n",
    "        fig, ax = matplot.subplots(figsize=(20,10))  \n",
    "        sns.heatmap(corr,annot=True,vmin=-1,vmax=1,cmap='Blues', linewidths=0, ax = ax)\n",
    "        Output1 = pandas.DataFrame(Output, columns= ['Feature','Uniqueness','Positive rel', 'inverse rel', 'Pos', 'Neg', 'No'])\n",
    "        return Output1\n",
    "\n",
    "    def EDA(df):\n",
    "        EDA = pandas.DataFrame((df.describe()).T)\n",
    "        EDA[\"Kurtosis\"] = df.kurtosis()\n",
    "        EDA[\"Skewness\"] = df.skew()\n",
    "        EDA[\"Range\"] = EDA['max'] -  EDA['min']\n",
    "        EDA[\"IQR\"] = EDA['75%'] -  EDA['25%']\n",
    "        EDA[\"Missing Values\"] = df.shape[0] - EDA[\"count\"]\n",
    "        print(\"Total Missing Values = \", EDA['Missing Values'].sum(), \"Data Points, Contributing to \", \n",
    "              (round(((EDA['Missing Values'].sum())/len(df)),2))*100,\"%\")\n",
    "        print(\"Columns with values as 0 \\n\\n\",pandas.Series((EDA.loc[EDA['min'] == 0]).index))\n",
    "        return EDA\n",
    "    \n",
    "    def NaN_treatment_median(df):\n",
    "        EDA_Summary = Perform_EDA.EDA(df)\n",
    "        Missing_Value_Columns = pandas.Series((EDA_Summary.loc[EDA_Summary['Missing Values'] != 0]).index)\n",
    "        len(Missing_Value_Columns)\n",
    "        for i in range(0,len(Missing_Value_Columns)):\n",
    "            df[Missing_Value_Columns[i]].fillna(df[Missing_Value_Columns[i]].median(), inplace = True)\n",
    "        return df\n",
    "    \n",
    "    def NaN_treatment_mean(df):\n",
    "        EDA_Summary = Perform_EDA.EDA(df)\n",
    "        Missing_Value_Columns = pandas.Series((EDA_Summary.loc[EDA_Summary['Missing Values'] != 0]).index)\n",
    "        len(Missing_Value_Columns)\n",
    "        for i in range(0,len(Missing_Value_Columns)):\n",
    "            df[Missing_Value_Columns[i]].fillna(df[Missing_Value_Columns[i]].mean(), inplace = True)\n",
    "        return df\n",
    "    \n",
    "    def Zero_Values_Treatment_Median(df):\n",
    "        EDA_Summary = Perform_EDA.EDA(df)\n",
    "        Zero_Value_Columns = pandas.Series((EDA_Summary.loc[EDA_Summary['min'] == 0]).index)\n",
    "        for i in range(0,len(Zero_Value_Columns)):\n",
    "            df[Zero_Value_Columns[i]].replace(0,(df[Zero_Value_Columns[i]]).median(), inplace = True)\n",
    "        return df\n",
    "    \n",
    "    def Zero_Values_Treatment_Mean(df):\n",
    "        EDA_Summary = Perform_EDA.EDA(df)\n",
    "        Zero_Value_Columns = pandas.Series((EDA_Summary.loc[EDA_Summary['min'] == 0]).index)\n",
    "        for i in range(0,len(Zero_Value_Columns)):\n",
    "            df[Zero_Value_Columns[i]].replace(0,(df[Zero_Value_Columns[i]]).mean(), inplace = True)\n",
    "        return df\n",
    "\n",
    "    def Missing_Values(df):\n",
    "        for i in range(0,len(df.columns)):\n",
    "            i = df.columns[i]\n",
    "            print(i,'\\n\\n',df[i].value_counts(),'\\n\\n',(df[i].value_counts()).sum(),'\\n\\n')\n",
    "        return Missing_Values\n",
    "    \n",
    "    def EDA_target(df,Y):\n",
    "        DF = pandas.DataFrame(Y.value_counts())\n",
    "        DF['Contribution'] = round(((DF['class'])/len(df)*100),2)\n",
    "        Missing_values = len(df) - (Y.value_counts()).sum()\n",
    "        print(\"Total Missing Values = \", Missing_values, \"Data Points, Contributing to \",\n",
    "              round(((Missing_values/len(df))*100),2),\"%\")\n",
    "        return DF\n",
    "    \n",
    "    def univariate_plots(Source):\n",
    "        a = pandas.Series(Source.select_dtypes(include=['int32','int64']).columns)\n",
    "        leng = len(a)\n",
    "        for j in range(0,len(a)):\n",
    "            f, axes = matplot.subplots(1, 2, figsize=(10, 10))\n",
    "            sns.boxplot(Source[a[j]], ax = axes[0])\n",
    "            sns.distplot(Source[a[j]], ax = axes[1])\n",
    "            matplot.subplots_adjust(top =  1.5, right = 10, left = 8, bottom = 1)\n",
    "\n",
    "        a = pandas.Series(Source.select_dtypes(include=['float64']).columns)\n",
    "        leng = len(a)\n",
    "        for j in range(0,len(a)):\n",
    "            matplot.Text('Figure for float64')\n",
    "            f, axes = matplot.subplots(1, 2, figsize=(10, 10))\n",
    "            sns.boxplot(Source[a[j]], ax = axes[0])\n",
    "            sns.distplot(Source[a[j]], ax = axes[1])\n",
    "            matplot.subplots_adjust(top =  1.5, right = 10, left = 8, bottom = 1)\n",
    "\n",
    "        a = pandas.Series(Source.select_dtypes(include=['object']).columns)\n",
    "        leng = len(a)\n",
    "        for j in range(0,len(a)):\n",
    "            matplot.subplots()\n",
    "            sns.countplot(Source[a[j]])\n",
    "\n",
    "class Evaluate_Model():\n",
    "    def __init__(self):\n",
    "        self.train_data = None\n",
    "        self.user_id = None\n",
    "        self.item_id = None\n",
    "    \n",
    "    \n",
    "    def plot_confusion_matrix(Y_test,Y_predict, target_names,title='Confusion matrix',cmap=None,normalize=True):\n",
    "        cm = metrics.confusion_matrix(Y_test, Y_predict)\n",
    "        accuracy = numpy.trace(cm) / float(numpy.sum(cm))\n",
    "        misclass = 1 - accuracy\n",
    "\n",
    "        if cmap is None:\n",
    "            cmap = matplot.get_cmap('Blues')\n",
    "\n",
    "        matplot.figure(figsize=(8, 6))\n",
    "        matplot.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        matplot.title(title)\n",
    "        matplot.colorbar()\n",
    "\n",
    "        if target_names is not None:\n",
    "            tick_marks = numpy.arange(len(target_names))\n",
    "            matplot.xticks(tick_marks, target_names, rotation=45)\n",
    "            matplot.yticks(tick_marks, target_names)\n",
    "\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, numpy.newaxis]\n",
    "\n",
    "\n",
    "        thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            if normalize:\n",
    "                matplot.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "            else:\n",
    "                matplot.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "        matplot.tight_layout()\n",
    "        matplot.ylabel('True label')\n",
    "        matplot.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "        matplot.show()\n",
    "        print(metrics.classification_report(Y_test, Y_predict))\n",
    "        model_performance = [metrics.accuracy_score(Y_test, Y_predict),metrics.recall_score(Y_test, Y_predict),\n",
    "                             metrics.precision_score(Y_test, Y_predict),metrics.f1_score(Y_test, Y_predict) ]\n",
    "        accuracy_report = pandas.DataFrame(model_performance, columns=['Model_Performance'], \n",
    "                                       index=['Accuracy','Recall','Precision','f1_Score'])\n",
    "        return accuracy_report\n",
    "    \n",
    "\n",
    "class Build_Model():\n",
    "    def __init__(self):\n",
    "        self.train_data = None\n",
    "        self.user_id = None\n",
    "        self.item_id = None\n",
    "        \n",
    "    def GS_DT(X_train, X_test, Y_train, Y_test,max_depth_start,max_depth_end,max_depth_jump,max_leaf_nodes_start,\n",
    "          max_leaf_nodes_end,max_leaf_nodes_jump, cv_count):\n",
    "        max_depth = numpy.arange(max_depth_start,max_depth_end,max_depth_jump)\n",
    "        max_leaf_nodes = numpy.arange(max_leaf_nodes_start,max_leaf_nodes_end,max_leaf_nodes_jump)\n",
    "        dt_Model = DecisionTreeClassifier(criterion = 'entropy', random_state=RandomState)\n",
    "        parameters = {'max_depth': max_depth, 'max_leaf_nodes':max_leaf_nodes}\n",
    "        dt_GS = GridSearchCV(dt_Model,parameters,cv=cv_count)\n",
    "        Y_train_1d = (Y_train.values).reshape(((Y_train.shape)[0]),)\n",
    "        dt_GS.fit(X_train,Y_train_1d)\n",
    "        dt_GS.predict(X_test)\n",
    "        depth = (pandas.Series(dt_GS.best_params_))[0]\n",
    "        leaf_node = (pandas.Series(dt_GS.best_params_))[1]\n",
    "        dt_model_reg = DecisionTreeClassifier(criterion = 'entropy', max_depth = depth, max_leaf_nodes = leaf_node, random_state= RandomState )\n",
    "        print(dt_model_reg)\n",
    "        dt_model_reg.fit(X_train, Y_train)\n",
    "        Tree_File = open('Decision_Tree.dot','w')\n",
    "        dot_data = tree.export_graphviz(dt_model_reg, out_file=Tree_File, feature_names = list(X_train), class_names = list(target_names))\n",
    "        Tree_File.close()\n",
    "        print (pandas.DataFrame(dt_model_reg.feature_importances_, columns = [\"Imp\"], index = X_train.columns))\n",
    "        Y_predict = dt_model_reg.predict(X_test)\n",
    "        dt_model_reg = plot_confusion_matrix(Y_test,Y_predict, target_names,title='Confusion matrix',cmap=None,normalize=True)\n",
    "        dt_model_reg = dt_model_reg.rename(columns={\"Model_Performance\" : \"Decision Tree Regularized\" })\n",
    "        dt_model_reg\n",
    "        return depth, leaf_node, dt_GS.get_params,dt_model_reg\n",
    "\n",
    "    def Log_model(X_train, X_test, Y_train, Y_test):\n",
    "        logmodel = LogisticRegression()\n",
    "        Log_model = logmodel.fit(X_train,Y_train)\n",
    "        Y_predict = logmodel.predict(X_test)\n",
    "        Log_model_scores = plot_confusion_matrix(Y_test,Y_predict, target_names,title='Confusion matrix',cmap=None,normalize=True)\n",
    "        Log_model_scores = Log_model_scores.rename(columns={\"Model_Performance\" : \"Logistic Regression\" })\n",
    "        Log_model_scores\n",
    "        return Log_model_scores\n",
    "\n",
    "    def Gau_NB_model(X_train, X_test, Y_train, Y_test):\n",
    "        NBmodel = GaussianNB()\n",
    "        Gau_NB_model = NBmodel.fit(X_train,Y_train)\n",
    "        Y_predict = NBmodel.predict(X_test)\n",
    "        Gau_NB_model_scores = plot_confusion_matrix(Y_test,Y_predict, target_names,title='Confusion matrix',cmap=None,normalize=True)\n",
    "        Gau_NB_model_scores = Gau_NB_model_scores.rename(columns={\"Model_Performance\" : \"Gaussian NB\" })\n",
    "        Gau_NB_model_scores\n",
    "        return Gau_NB_model_scores\n",
    "\n",
    "    def GS_KNN(X_train,Y_train,X_test,Y_test, n_neighbors_start, n_neighbors_end, n_neighbors_jump,cv_count):\n",
    "        X_train = preprocessing.scale(X_train)\n",
    "        X_test = preprocessing.scale(X_test)\n",
    "        k = numpy.arange(n_neighbors_start, n_neighbors_end, n_neighbors_jump)\n",
    "        KNN = KNeighborsClassifier()\n",
    "        parameters = {'n_neighbors': k}\n",
    "        GS_KNN = GridSearchCV(KNN,parameters,cv=cv_count)\n",
    "        Y_train_1d = (Y_train.values).reshape(((Y_train.shape)[0]),)\n",
    "        GS_KNN.fit(X_train,Y_train_1d)\n",
    "        GS_KNN.predict(X_test)\n",
    "        n_neighbors = (pandas.Series(GS_KNN.best_params_))[0]\n",
    "        KNN_model = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "        print(KNN_model)\n",
    "        KNN_model.fit(X_train, Y_train)\n",
    "        Y_predict = KNN_model.predict(X_test)\n",
    "        KNN_model_Scores = plot_confusion_matrix(Y_test,Y_predict, target_names,title='Confusion matrix',cmap=None,normalize=True)\n",
    "        KNN_model_Scores = KNN_model_Scores.rename(columns={\"Model_Performance\" : \"K Nearest Neighbors\" })\n",
    "        KNN_model_Scores\n",
    "        return n_neighbors, GS_KNN.get_params,KNN_model_Scores\n",
    "\n",
    "    def GS_RandomForest(X_train,Y_train,X_test,Y_test, n_estimator_start, n_estimator_end, n_estimator_jump,cv_count):\n",
    "        n = numpy.arange(n_estimator_start, n_estimator_end, n_estimator_jump)\n",
    "        RF = RandomForestClassifier(random_state=RandomState)\n",
    "        parameters = {'n_estimators': n}\n",
    "        GS_RandomForest = GridSearchCV(RF,parameters,cv=cv_count)\n",
    "        Y_train_1d = (Y_train.values).reshape(((Y_train.shape)[0]),)\n",
    "        GS_RandomForest.fit(X_train,Y_train_1d)\n",
    "        GS_RandomForest.predict(X_test)\n",
    "        n_estimator = (pandas.Series(GS_RandomForest.best_params_))[0]\n",
    "        RF = RandomForestClassifier(n_estimators = n_estimator, random_state=RandomState)\n",
    "        print(RF)\n",
    "        RF.fit(X_train, Y_train)\n",
    "        Y_predict = RF.predict(X_test)\n",
    "        RF_Scores = plot_confusion_matrix(Y_test,Y_predict, target_names,title='Confusion matrix',cmap=None,normalize=True)\n",
    "        RF_Scores = RF_Scores.rename(columns={\"Model_Performance\" : \"Random Forest\" })\n",
    "        RF_Scores\n",
    "        return n_estimator, GS_RandomForest.get_params,RF_Scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
